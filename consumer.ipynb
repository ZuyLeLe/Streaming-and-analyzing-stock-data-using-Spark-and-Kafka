{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.927811700Z",
     "start_time": "2024-01-21T14:43:35.616273400Z"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StringType, StructField, StructType, ArrayType, LongType\n",
    "import pyspark.sql.functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "topic = \"Stock_data\"\n",
    "server = 'localhost:9092'\n",
    "scala_version = '2.12'\n",
    "spark_version = '3.5.0'\n",
    "packages = [\n",
    "    f'org.apache.spark:spark-sql-kafka-0-10_{scala_version}:{spark_version}',\n",
    "    'org.apache.kafka:kafka-clients:3.6.1'\n",
    "]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.940480800Z",
     "start_time": "2024-01-21T14:43:35.927811700Z"
    }
   },
   "id": "1ecc340780b0298a",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_spark_session():\n",
    "    try:\n",
    "        spark_session = (SparkSession.builder.appName(\"Reddit_comments_analysis\")\n",
    "                         .master(\"local\").config(\"spark.jars.packages\", \",\".join(packages))\n",
    "                         .getOrCreate())\n",
    "        spark_session.sparkContext.setLogLevel(\"ERROR\")\n",
    "        print('Spark session created successfully')\n",
    "        return spark_session\n",
    "    except Exception:\n",
    "        print(\"Couldn't create the spark session\")\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.942478400Z",
     "start_time": "2024-01-21T14:43:35.935928200Z"
    }
   },
   "id": "5732698f0cab77a5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_initial_dataframe(spark):\n",
    "    try:\n",
    "        init_df = (spark.readStream.format(\"kafka\")\n",
    "                   .option(\"kafka.bootstrap.servers\", server)\n",
    "                   .option(\"subscribe\", topic)\n",
    "                   .option(\"startingOffsets\", \"latest\")\n",
    "                   .load())\n",
    "        print(\"Initial dataframe created successfully\")\n",
    "        return init_df\n",
    "    except Exception as e:\n",
    "        print(f\"Initial dataframe couldn't be created due to exception: {e}\")\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.955348700Z",
     "start_time": "2024-01-21T14:43:35.943057700Z"
    }
   },
   "id": "53d5189cf2d3110a",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def create_final_dataframe(df):\n",
    "    schema = StructType([StructField('date', StringType(), True),\n",
    "                         StructField('open', StringType(), True),\n",
    "                         StructField('high', StringType(), True),\n",
    "                         StructField('low', StringType(), True),\n",
    "                         StructField('close', StringType(), True),\n",
    "                         StructField('volume', StringType(), True),\n",
    "                         ])\n",
    "    df = df.selectExpr(\"CAST(value AS STRING)\", \"CAST(timestamp AS TIMESTAMP)\")\n",
    "    df = df.withColumn(\"value\", F.from_json(\"value\", schema)).select(\"value.*\", \"timestamp\")\n",
    "    \n",
    "    return df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:44:07.848839Z",
     "start_time": "2024-01-21T14:44:07.845310200Z"
    }
   },
   "id": "586b2f57853947be",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def start_streaming(df):\n",
    "    print(\"Streaming is being started...\")\n",
    "    query = df \\\n",
    "        .writeStream \\\n",
    "        .trigger(processingTime='3 seconds') \\\n",
    "        .outputMode(\"append\") \\\n",
    "        .format(\"memory\") \\\n",
    "        .queryName(\"reddit_comments\") \\\n",
    "        .start()\n",
    "    return query.awaitTermination(1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.974066600Z",
     "start_time": "2024-01-21T14:43:35.959369100Z"
    }
   },
   "id": "8ad3e6d8f8e55915",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from IPython.core.display_functions import clear_output\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "def write_streaming_data():\n",
    "    spark = create_spark_session()\n",
    "    df = create_initial_dataframe(spark)\n",
    "    df_final = create_final_dataframe(df)\n",
    "    start_streaming(df_final)\n",
    "\n",
    "    while True:\n",
    "        spark_df = spark.sql('SELECT * FROM reddit_comments')\n",
    "        result = spark_df.toPandas()\n",
    "        # subreddit_predictor(result)\n",
    "        display(result.tail(10))\n",
    "        sleep(3)\n",
    "        clear_output(wait=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-21T14:43:35.974066600Z",
     "start_time": "2024-01-21T14:43:35.965429200Z"
    }
   },
   "id": "f2ca9b83bf24ead5",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "                        date                open                high  \\\n0  2024-01-19 09:46:00-05:00  145.39999389648438   145.4499969482422   \n1  2024-01-19 09:47:00-05:00  145.44000244140625  145.40499877929688   \n2  2024-01-19 09:48:00-05:00  145.40499877929688  145.39999389648438   \n3  2024-01-19 09:49:00-05:00  145.38999938964844  145.05999755859375   \n4  2024-01-19 09:50:00-05:00   145.0399932861328  145.08999633789062   \n\n                  low               close   volume               timestamp  \n0   145.3300018310547   145.4499969482422  69222.0 2024-01-21 21:44:15.330  \n1  145.27000427246094  145.40499877929688  74786.0 2024-01-21 21:44:18.335  \n2  145.35499572753906  145.39999389648438  75332.0 2024-01-21 21:44:21.339  \n3   145.0449981689453  145.05999755859375  72738.0 2024-01-21 21:44:24.344  \n4  144.97000122070312  145.08999633789062  69344.0 2024-01-21 21:44:27.347  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>date</th>\n      <th>open</th>\n      <th>high</th>\n      <th>low</th>\n      <th>close</th>\n      <th>volume</th>\n      <th>timestamp</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2024-01-19 09:46:00-05:00</td>\n      <td>145.39999389648438</td>\n      <td>145.4499969482422</td>\n      <td>145.3300018310547</td>\n      <td>145.4499969482422</td>\n      <td>69222.0</td>\n      <td>2024-01-21 21:44:15.330</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2024-01-19 09:47:00-05:00</td>\n      <td>145.44000244140625</td>\n      <td>145.40499877929688</td>\n      <td>145.27000427246094</td>\n      <td>145.40499877929688</td>\n      <td>74786.0</td>\n      <td>2024-01-21 21:44:18.335</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2024-01-19 09:48:00-05:00</td>\n      <td>145.40499877929688</td>\n      <td>145.39999389648438</td>\n      <td>145.35499572753906</td>\n      <td>145.39999389648438</td>\n      <td>75332.0</td>\n      <td>2024-01-21 21:44:21.339</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2024-01-19 09:49:00-05:00</td>\n      <td>145.38999938964844</td>\n      <td>145.05999755859375</td>\n      <td>145.0449981689453</td>\n      <td>145.05999755859375</td>\n      <td>72738.0</td>\n      <td>2024-01-21 21:44:24.344</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2024-01-19 09:50:00-05:00</td>\n      <td>145.0399932861328</td>\n      <td>145.08999633789062</td>\n      <td>144.97000122070312</td>\n      <td>145.08999633789062</td>\n      <td>69344.0</td>\n      <td>2024-01-21 21:44:27.347</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    write_streaming_data()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "e82ed696c571b32f",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
